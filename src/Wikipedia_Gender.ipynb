{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linguistic gender biases in Wikipedia:\n",
    "### Give me an overview and I will tell you the gender of the character (FIND SOMETHING FANCY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Wikipedia has become a very large source of information. By November 2019, the number of entries in the English Wikipedia was above 5M [[1]](https://en.wikipedia.org/wiki/Wikipedia:Statistics#Page_views) and it was increasing everyday at a rate of 500 entries in averge. \n",
    "\n",
    "In previous studies Wagner et al [[2]](https://arxiv.org/abs/1501.06307) shown how gender biases manifest in Wikipedia in the way women and men are portrayed. In a different study, Graells-Garrido et al [[3]](https://labtomarket.files.wordpress.com/2018/01/wiki_gender_bias.pdf) shown that women biographies are more likely to contain sex-related content. Along with these studies, several others have studied topic-related biases in the way women are portrayed but we can also take a look from the linguistic perspective. \n",
    "\n",
    "Linguistic biases is defined as a systematic asymmetry in word choice that reflects the social-category cognitions that are applied to the described group or individual(s) [[4]](https://oxfordre.com/communication/communication/view/10.1093/acrefore/9780190228613.001.0001/acrefore-9780190228613-e-439). We want to analyze how men and women are protrayed and more specifically, the adjectives used to describe them with the aim to spot possible gender biases from a linguistic perspective. To do so, we will use the overview of the biographies in the English Wikipedia together with other characteristics of the people we are analysing.\n",
    "\n",
    "Initially we will start by exploring the dataset, i.e. ratio of male and female entries, presence of other genders, etc. Later, we will explore the language used on the overviews by focusing on the adjectives. We restrict the analysis to adjectives given the level of abstraction they provide [[5]](https://www.aaai.org/ocs/index.php/ICWSM/ICWSM15/paper/download/10539/10513). This analysis will be conducted by first extracting the most frequent adjectives from all the biographies used. With them we will build a vocabulary and use it to create a representation of each character based on the adjectives in our vocabulary that appear in its biography. \n",
    "\n",
    "Once we have a vectorial representation of each person, we will create a model using logistic regression that will try to predict if a biography belongs to a male or female. If this task becomes feasible, it means there is a pattern in the usage of language that allows us to make a distinction between genders, highlighting the presence of a bias. Will our model succeed in its tasks? Continue with us to discover our results! \n",
    "\n",
    "[[1] Wikipedia Statistics](https://en.wikipedia.org/wiki/Wikipedia:Statistics#Page_views)\n",
    "\n",
    "[[2] It's a Man's Wikipedia? Assessing Gender Inequality in an Online Encyclopedia](https://arxiv.org/abs/1501.06307)\n",
    "\n",
    "[[3] First Women, Second Sex: Gender Bias in Wikipedia](https://labtomarket.files.wordpress.com/2018/01/wiki_gender_bias.pdf)\n",
    "\n",
    "[[4] Oxford Research Encyclopedia](https://oxfordre.com/communication/communication/view/10.1093/acrefore/9780190228613.001.0001/acrefore-9780190228613-e-439)\n",
    "\n",
    "[[5] Linguistic Bias in Collaboratively Produced Biographies: Crowdsourcing Social Stereotypes?](https://www.aaai.org/ocs/index.php/ICWSM/ICWSM15/paper/download/10539/10513)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing and extraction\n",
    "\n",
    "As stated before, we are only interested in analysing the biographies of Wikipedia, so we need to filter them. More precisely, we will use the overview of the biographies in the English Wikipedia. In order to do that, we followed these steps:\n",
    "\n",
    "1. We use the [Wikidata Human Gender Indicators (WHGI)](#http://whgi.wmflabs.org) dataset, which contains all the biography articles in all Wikipedias and it is updated weekly. From this dataset (November 2019 version), we get all the biographies that are in the English Wikipedia and that have a gender. For each entry, we get the Q-id, gender and occupation. We use this dataset because it is more updated than the Wikidata one in cluster (dated from 2017). Code in [here](createDataset/1_extract_qid_wikidata.py).\n",
    "\n",
    "\n",
    "2. Then, we need to link the previous information with the Wikipedia article. For that, we need to use Wikidata dataset found in the cluster. First, we filter the entries that we obtain in the previous step and obtain the name of the entry in the English Wikipedia. Code in [here](createDataset/2_extract_people_wikidata.py).\n",
    "\n",
    "\n",
    "3. Next, we have to obtain the biographies from Wikipedia dataset. To do that, we simply join the English Wikipedia dataset (also found in the cluster) with the one obtained in the previous step by the Wikipedia title, which is unique. Code in [here](createDataset/3_filter_people_enwiki.py).\n",
    "\n",
    "\n",
    "4. Following, we need to extract and clear the overview of the wikipedia text. First, we find the end of the overview (which usually starts either with `==` or `[[Category:` ). Then we clear the references, comments from the editors, quotes abd withs inside parenthesis or brackets. Code in [here](createDataset/4_extract_overview_enwiki.py).\n",
    "\n",
    "\n",
    "5. Finally, as it will be shown later in the analysis, we filter the database according to gender of the people. We keep only the male and the female as the other gender represent less than 1% of the whole dataset. Code in [here](createDataset/5_filter_female_male.py). \n",
    "\n",
    "The final dataset contains 1,383,430 entries and it has the following schema:\n",
    "```\n",
    "root\n",
    " |-- gender: string (nullable = true)\n",
    " |-- id: string (nullable = true)\n",
    " |-- name: string (nullable = true)\n",
    " |-- occupation: string (nullable = true)\n",
    " |-- overview: string (nullable = true)\n",
    " |-- wiki-title: string (nullable = true)\n",
    "```\n",
    "\n",
    "where the gender is represented by the its Wikidata code, the ID is the unique code from Wikidata, the name is the name of the person (not necessarily unique), the occupation is a list of codes from Wikidata corresponding to the occupations of one person, the overview is the clean introduction of Wikipedia and the wiki-title is the unique name from the English Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(8)\n",
    "\n",
    "# set font size for plots\n",
    "matplotlib.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries to convert wikidata codes to english words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dictionaries\n",
    "\n",
    "In this section, we load the dictionaries used to tranform the codes in the dataset to the corresponding name (dict_genders and dict_occupations). We also load a dictionary to group the occupations by field and the subjectivity lexicon used to analyze the adjectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Gender dictionary\n",
    "with open('../data/dict_genders.json') as json_file:\n",
    "    line = json_file.readline()\n",
    "    dict_genders = json.loads(line)\n",
    "    \n",
    "# Open occupations dictionary\n",
    "dict_occupations = {}\n",
    "with open('../data/dict_occupations.json') as json_file:\n",
    "    content = json_file.readlines()\n",
    "    for line in content:\n",
    "        occ = json.loads(line)\n",
    "        dict_occupations.update(occ)\n",
    "        \n",
    "# Observation: We need dict_categories_occupations.json in the data folder\n",
    "# Open occupations categories dictionary\n",
    "with open('../data/dict_categories_occupations.json') as json_file:\n",
    "    line = json_file.readline()\n",
    "    dict_cat_occ = json.loads(line)\n",
    "\n",
    "# Open subjectivity lexicon\n",
    "subjectivity_dictionary = {}\n",
    "    \n",
    "with open('../data/subjectivity_dictionary.json', 'r') as json_file:\n",
    "    for item in eval(json_file.readline()):\n",
    "        subjectivity_dictionary.update({item['word']: (item['strength'], item['subj'])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender analysis\n",
    "\n",
    "In this section, we will analyze all the genders in the dataset. Here, we use the dataset extracted after step 4 from the section [data preprocessing and extraction](#Data-preprocessing-and-extraction).\n",
    "\n",
    "We find that there are 9 different genders in the dataset. However, we group them in male, female and other (because the non-binary genders have very few entries). Since the \"other\" genders represent less than 1% of the whole dataset, we decide to drop them and focus our research on male and female genders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_PATH = \"../data/\"\n",
    "WIKI_DATA = os.path.join(LOCAL_PATH, \"overview_wikipedia.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# create the context\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# load data\n",
    "df = spark.read.json(WIKI_DATA)\n",
    "\n",
    "# explode the gender column (create multiple entries for people with a list of genders)\n",
    "df = df.withColumn(\"gender\", split(regexp_replace(regexp_replace(regexp_replace(regexp_replace(df['gender'], \\\n",
    "                                                            '\\\\[', ''), '\\\\]', ''), ' ', ''),\"'\", \"\"), \",\"))\n",
    "df = df.withColumn(\"gender\", df['gender'][0])\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by gender and compute count\n",
    "gender_counts = df.groupBy(\"gender\").agg(count(\"*\").alias(\"count\")).sort(desc(\"count\"))\n",
    "gender_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In total there are {} different genders\".format(gender_counts.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender(gender):\n",
    "    return dict_genders.get(gender, \"other\")\n",
    "\n",
    "# get the gender (male, female or other) from the id\n",
    "udf_get_gender = udf(get_gender)\n",
    "gender_counts = gender_counts.withColumn(\"gender\", udf_get_gender(\"gender\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the other genders\n",
    "gender_counts_grouped = gender_counts.groupBy(\"gender\").agg(sum(\"count\").alias(\"count\")).sort(desc(\"count\"))\n",
    "gender_counts_grouped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to pandas\n",
    "gender_counts_pd = gender_counts_grouped.toPandas()\n",
    "\n",
    "pl = gender_counts_pd.plot(kind=\"bar\", x=\"gender\", y=\"count\", figsize=(15, 7), log=True, \\\n",
    "                           alpha=0.5, color=\"green\", rot=0)\n",
    "pl.set_xlabel(\"Gender\")\n",
    "pl.set_ylabel(\"Number of biographies (Log scale)\")\n",
    "pl.set_title(\"Number of biographies by gender\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention**: The y-axis is in log-scale!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = gender_counts_pd['count'].sum()\n",
    "n_male = gender_counts_pd[gender_counts_pd['gender'] == 'male']['count'].values[0]\n",
    "n_female = gender_counts_pd[gender_counts_pd['gender'] == 'female']['count'].values[0]\n",
    "n_other = n_total - n_male - n_female\n",
    "\n",
    "print(\"{:.2f}% of the entries are male\".format(n_male/n_total*100))\n",
    "print(\"{:.2f} % of the entries are female\".format(n_female/n_total*100))\n",
    "print(\"{:.2f} % of the entries are other gender\".format(n_other/n_total*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these numbers, we decide to **drop the other genders** and continue our analysis with only female and male."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction\n",
    "### TODO: :\n",
    "Explain process of extraction of the data; combination of wikimedia and wikipedia; preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_PATH = \"../data/\"\n",
    "WIKI_DATA_FULL = os.path.join(LOCAL_PATH, \"wikipedia_male_female.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data frame\n",
    "df_full = spark.read.json(WIKI_DATA_FULL)\n",
    "df_full.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following steps we are going to explore how women are represented in wikipedia. First, we will start with some basic statistics like the fraction of entries that correspond to each gender and how this varies along different occupations. After, we will enter in the core analysis of the project by analysing the language used to present the different characters. The idea is to focus on the adjectives used in the overviews and look for a bias between male and female representations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data translation\n",
    "Translate wikimedia codes to the actual meaning in terms of gender and occupation.\n",
    "**Note:** Since we are interested in both gender and occupation, when the translation from wikimedia code to words is perform those people without associated occupation will be dropped from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to translate a code into a category\n",
    "def translate(mapping):\n",
    "    def translate_(col):\n",
    "        return mapping.get(col)\n",
    "    return udf(translate_, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate gender and occupations codes into corresponding labels\n",
    "df_full = df_full.withColumn('gender', translate(dict_genders)('gender'))\\\n",
    "       .withColumn('occupation', explode(split(regexp_replace(regexp_replace(regexp_replace\\\n",
    "                                (regexp_replace(df_full['occupation'], '\\\\[', ''), '\\\\]', ''), ' ', ''),\"'\", \"\"), \",\")))\\\n",
    "       .filter(col('occupation') != '')\\\n",
    "       .withColumn('occupation', translate(dict_occupations)('occupation'))\\\n",
    "       .withColumn('field', translate(dict_cat_occ)('occupation'))\n",
    "\n",
    "# drop column 'wiki-title' to ease visualization \n",
    "df_full_viz = df_full.drop('wiki-title')\n",
    "df_full_viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to know how many males and females are in the data frame\n",
    "# Observation: When occupation translation is done, the observations without a label are dropped, that's why, there are less male and female\n",
    "df_full.registerTempTable(\"df\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT gender, count(DISTINCT id) as count\n",
    "FROM df\n",
    "GROUP BY gender\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "\n",
    "gender_counts = spark.sql(query)\n",
    "gender_counts = gender_counts.toPandas()\n",
    "gender_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = gender_counts.plot(kind=\"bar\", x=\"gender\", y=\"count\", figsize=(15, 7), log=False, \\\n",
    "                        alpha=0.5, color=\"green\", rot=0)\n",
    "for p in pl.patches:\n",
    "    disp= '{:.1f}'.format(p.get_height())\n",
    "    pl.annotate(disp, (p.get_x(), p.get_height()*1.015))\n",
    "\n",
    "pl.set_xlabel(\"Gender\")\n",
    "pl.set_ylabel(\"Number of biographies\")\n",
    "pl.set_title(\"Number of biographies by gender\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occupation distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.registerTempTable(\"df\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT field, count(DISTINCT id) as count\n",
    "FROM df\n",
    "WHERE field IS NOT NULL\n",
    "GROUP BY field\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "\n",
    "occu_cat_counts = spark.sql(query)\n",
    "occu_cat_counts = occu_cat_counts.toPandas()\n",
    "occu_cat_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = occu_cat_counts.plot(kind=\"bar\", x=\"field\", y=\"count\", figsize=(15, 7), log=False, \\\n",
    "                          alpha=0.5, color=\"green\", rot=0)\n",
    "pl.set_xlabel(\"Field of occupation\")\n",
    "pl.set_ylabel(\"Number of biographies\")\n",
    "pl.set_title(\"Number of biographies by field of occupation\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common occupation among our characters is **Sports** followed by **Artist** and **Politics**. The group **None** represents all those occupations that did not match any of the previous groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = occu_cat_counts['count'].sum()\n",
    "n_sports = occu_cat_counts[occu_cat_counts['field'] == 'Sports']['count'].values[0]\n",
    "n_artist = occu_cat_counts[occu_cat_counts['field'] == 'Artist']['count'].values[0]\n",
    "n_politics = occu_cat_counts[occu_cat_counts['field'] == 'Politics']['count'].values[0]\n",
    "\n",
    "print(\"{:.2f}% of the entries work in the sports field\".format(n_sports/n_total*100))\n",
    "print(\"{:.2f}% of the entries work in the artistic field\".format(n_artist/n_total*100))\n",
    "print(\"{:.2f}% of the entries work in the politics field\".format(n_politics/n_total*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender by occupation\n",
    "\n",
    "How are the distinct genders represented within the different occupational groups? Is there any group where women have a greater representation than men?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.registerTempTable(\"df\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT field, gender, count(DISTINCT id) as count\n",
    "FROM df\n",
    "WHERE field IS NOT NULL\n",
    "GROUP BY field, gender\n",
    "ORDER BY field, gender\n",
    "\"\"\"\n",
    "\n",
    "occu_gender_counts = spark.sql(query)\n",
    "occu_gender_counts = occu_gender_counts.toPandas()\n",
    "occu_gender_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can point out different details: \n",
    "- Female biographies are less in all fields except **Model** which is associated to the mode industry. In this case, for each 5 biographies related to female characters we have one male biography.\n",
    "- **Religion** and **Military** are the groups where the ratio female:male becomes larger. In religion related biographies for each female we will find 69 males. In military related ones, for each female we will find 62 males.\n",
    "- The most balanced occupational field is **Artist** where the ratio female:male is of 1:3\"\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_count = occu_gender_counts[occu_gender_counts['gender'] == 'male']['count'].tolist()\n",
    "female_count = occu_gender_counts[occu_gender_counts['gender'] == 'female']['count'].tolist()\n",
    "index = occu_gender_counts['field'].unique().tolist()\n",
    "occ_by_gender = pd.DataFrame({'male': male_count, 'female': female_count}, index=index)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(15, 14))\n",
    "pl = occ_by_gender.plot(kind=\"bar\", log=False, alpha=0.5, color=[\"green\", \"red\"], rot=0, ax=ax[0])\n",
    "pl.set_xlabel(\"Field of occupation\")\n",
    "pl.set_ylabel(\"Number of biographies\")\n",
    "pl.set_title(\"Number of biographies by gender and field of occupation\");\n",
    "             \n",
    "occ_by_gender['ratio'] = occ_by_gender.apply(lambda x: x.male / x.female, axis=1)\n",
    "\n",
    "pl = occ_by_gender.plot(kind=\"bar\", y='ratio', alpha=0.5, color='green', rot=0, ax=ax[1])\n",
    "for p in ax[1].patches:\n",
    "    disp= '{:.1f}'.format(p.get_height())\n",
    "    ax[1].annotate(disp, (p.get_x() * 1.005, p.get_height() +0.5))\n",
    "pl.set_xlabel(\"Field of occupation\")\n",
    "pl.set_ylabel(\"Number of biographies\")\n",
    "pl.set_title(\"Ratio of female:male biographies by field of occupation\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjectives analysis\n",
    "\n",
    "In this section we analyze the adjectives used to describe the different characters. We use the subjectivity lexicon version used in \"Theresa Wilson, Janyce Wiebe, and Paul Hoffmann (2005). Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis. Proc. of HLT-EMNLP-2005.\" [[1]](https://mpqa.cs.pitt.edu/lexicons/subj_lexicon/) to determine the degree of subjectivity of the vocabularity. It also allows us to determine if the given adjectives are usually employed with a positive or negative connotation. \n",
    "\n",
    "First, we will start by associating to each adjective its subjectivity and strength values. We will then visualize the most common adjectives by gender and their associated degree of strength (negative, positive or neutral). Finally, we will study the usage of strongly subjective adjectives based on the gender. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associate subjectivity level and strength to each value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "LOCAL_PATH = \"../data/\"\n",
    "\n",
    "# most common adjectives used in male and female overviews\n",
    "ADJ_MALE = os.path.join(LOCAL_PATH, \"count_male_adjectives.json\")\n",
    "ADJ_FEM = os.path.join(LOCAL_PATH, \"count_female_adjectives.json\")\n",
    "\n",
    "most_common_adj_male = spark.read.json(ADJ_MALE)\n",
    "most_common_adj_fem = spark.read.json(ADJ_FEM)\n",
    "\n",
    "# overviews adjectives for all characters\n",
    "WIKI_MALE = os.path.join(LOCAL_PATH, \"wikipedia_male_adjectives.json\")\n",
    "WIKI_FEM = os.path.join(LOCAL_PATH, \"wikipedia_female_adjectives.json\")\n",
    "\n",
    "df_male = spark.read.json(WIKI_MALE)\n",
    "df_fem = spark.read.json(WIKI_FEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most frequent adjectives for each gender\n",
    "most_common_adj_male = most_common_adj_male.orderBy(desc(\"count\"))\n",
    "most_common_adj_fem = most_common_adj_fem.orderBy(desc(\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain subjectivity degree and strength of the word\n",
    "def get_subjectivity(adj):\n",
    "    return subjectivity_dictionary.get(adj)[1]\n",
    "\n",
    "def get_strength(adj):\n",
    "    return subjectivity_dictionary.get(adj)[0]\n",
    "\n",
    "udf_get_subj = udf(get_subjectivity)\n",
    "udf_get_strength = udf(get_strength)\n",
    "\n",
    "most_common_adj_male = most_common_adj_male.withColumn(\"subjectivity\", udf_get_subj(\"adjectives\"))\n",
    "most_common_adj_fem = most_common_adj_fem.withColumn(\"subjectivity\", udf_get_subj(\"adjectives\"))\n",
    "most_common_adj_male = most_common_adj_male.withColumn(\"strength\", udf_get_strength(\"adjectives\"))\n",
    "most_common_adj_fem = most_common_adj_fem.withColumn(\"strength\", udf_get_strength(\"adjectives\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show most common adjectives in each case with their subjectivity and strength\n",
    "most_common_adj_male.show(5)\n",
    "most_common_adj_fem.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now we have obtained the most used adjectives for each gender and associate them with their degree of strength and subjectivity. If we compare the top-five adjectives of each gender, we can see there are 3 shared words: **popular**, **best** and **notable**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: INTEGRATE THIS WITH ANALYSIS ABOUT LENGTH OF OVERVIEWS! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total number of adjectives per overview\n",
    "def get_nb_adjs(list_adj):\n",
    "    return len(list_adj)\n",
    "\n",
    "udf_get_nb_adjs = udf(get_nb_adjs)\n",
    "\n",
    "df_male_totals = df_male.withColumn(\"nb-adjs\", udf_get_nb_adjs(\"adjectives\"))\n",
    "df_fem_totals = df_fem.withColumn(\"nb-adjs\", udf_get_nb_adjs(\"adjectives\"))\n",
    "\n",
    "# compute statistics\n",
    "def stats_nb_adj(df, gender):\n",
    "    count_adj = df.agg(mean(col(\"nb-adjs\")), stddev(col(\"nb-adjs\"))).collect()\n",
    "    print('{}.\\tAverage num of adjectives: {:.2f}. Std of the sample: {:.2f}'.\\\n",
    "          format(gender, count_adj[0][0], count_adj[0][1]) )\n",
    "\n",
    "stats_nb_adj(df_male_totals, 'Male')\n",
    "stats_nb_adj(df_fem_totals, 'Female')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word cloud for the most common adjectives\n",
    "\n",
    "Visualization of the most common adjectives used in the overviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_male_dict = most_common_adj_male.select('adjectives', 'count').toPandas().set_index('adjectives').T.to_dict('records')\n",
    "adj_female_dict = most_common_adj_fem.select('adjectives', 'count').toPandas().set_index('adjectives').T.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map subjectity of words to colors\n",
    "word_to_color = dict()\n",
    "\n",
    "for word in subjectivity_dictionary:\n",
    "    if subjectivity_dictionary[word][1] == \"positive\":\n",
    "        word_to_color[word] = 'forestgreen' \n",
    "    if subjectivity_dictionary[word][1] == \"negative\":\n",
    "        word_to_color[word] = 'crimson' \n",
    "    if subjectivity_dictionary[word][1] == \"neutral\":\n",
    "        word_to_color[word] = 'grey' \n",
    "\n",
    "def color_func(word, *args, **kwargs):\n",
    "    try:\n",
    "        color = word_to_color[word]\n",
    "    except KeyError:\n",
    "        color = '#000000' # black\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordcloud(mask_image, adj_dict):\n",
    "    mask_ = np.array(Image.open(mask_image))\n",
    "    wc = WordCloud(background_color=\"white\", max_words=500, mask=mask_, \n",
    "               contour_width=3, contour_color='peru', color_func=color_func)\n",
    "    # generate word cloud\n",
    "    wc.generate_from_frequencies(adj_dict[0])\n",
    "    \n",
    "    return wc\n",
    "\n",
    "\n",
    "def viz_wordcloud(wc_male, wc_fem):\n",
    "    fig,ax = plt.subplots(1,2, figsize=(20,20))\n",
    "    ax[0].imshow(wc_male, cmap=plt.cm.gray, interpolation=\"bilinear\")\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[1].imshow(wc_fem, cmap=plt.cm.gray, interpolation=\"bilinear\")\n",
    "    ax[1].axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following word cloud shows the 500 most common adjectives used in male and female biographies. The size of the word is proportional to the frequency of appearance while the color represents the connotation. In green we see the adjectives ranked as positive, in red the ones ranked negative and in grey the ones considered as neutral. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_male   = generate_wordcloud(\"male.png\", adj_male_dict)\n",
    "wc_female = generate_wordcloud(\"female.png\", adj_female_dict)\n",
    "\n",
    "viz_wordcloud(wc_male, wc_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both genders we see a higher presence of positive-related words as well as some shared adjectives as we showed in the previous subsection. Given the results of this first inspection, we will conduct further quantitative research to see the usage of positive versus negative connoted words and their degree of subjectivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage of strongly subjective adjectives depending on the gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity_strength(df):\n",
    "    \"\"\"\n",
    "    compute number of adjectives per strength and subjectivity used in the overviews\n",
    "    \"\"\"\n",
    "    # count adj per strength and subjectivity\n",
    "    overview_subjectivity = df.groupBy('strength', 'subjectivity').\\\n",
    "    agg(sum('count').alias('sum_')).orderBy(desc('sum_'))\n",
    "    \n",
    "    overview_subjectivity = overview_subjectivity.replace('', 'None')\n",
    "    \n",
    "    # compute percentage of adj in the strongly subjective category\n",
    "    strong_adj = df.where((col(\"strength\") == \"strongsubj\")).\\\n",
    "    groupBy('strength', 'subjectivity').agg({'count':'sum'}).\\\n",
    "    where((col(\"subjectivity\") == \"positive\") | (col(\"subjectivity\") == \"negative\"))\n",
    "    \n",
    "    strong_adj = strong_adj.\\\n",
    "    withColumn(\"percentage\", 100*strong_adj['sum(count)']/ df.agg({'count':'sum'}).\\\n",
    "               collect()[0][0])\n",
    "\n",
    "    return overview_subjectivity, strong_adj\n",
    "    \n",
    "# compute statistics for each gender\n",
    "os_male, strength_adj_male = subjectivity_strength(most_common_adj_male)\n",
    "os_female, strength_adj_female = subjectivity_strength(most_common_adj_fem)\n",
    "\n",
    "# show results in a single table\n",
    "os_genders = os_male.withColumnRenamed('sum_', 'male_sum').\\\n",
    "join(os_female.withColumnRenamed('sum_', 'female_sum'), ['strength', 'subjectivity'])\n",
    "\n",
    "strength_genders = strength_adj_male.withColumnRenamed('percentage', 'male_percentage').\\\n",
    "join(strength_adj_female.withColumnRenamed('percentage', 'female_percentage'), ['strength', 'subjectivity']).\\\n",
    "drop('sum(count)')\n",
    "\n",
    "# visualize\n",
    "os_genders_pd = os_genders.toPandas()\n",
    "strength_genders_pd = strength_genders.toPandas().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "\n",
    "In this section, we build a model with the most common adjectives in the overviews of the biographies to find out if there is any bias on how males and females are described. We force to have a balanced dataset and our hypothesis is that if the accuracy obtained is higher than 0.5 there is a bias, because the model is able to learn something from the features. Therefore, if that is the case, we will analyze which adjectives create that bias from the coefficients of the model.\n",
    "\n",
    "**First approach**: Since the whole dataset is very unbalanced, we take the 100 most common adjectives from male and the 100 most common adjectives from female biographies, and we merge them. That gives us a total of 112 adjectives to use as features of our model. To encode these features, we create a vector of features with 1 if the adjective is present in the overview and 0 if not. The output we want to predict corresponds to the gender of the biographies. We use 0 for male and 1 for female. Then, we train a logistic regression model and obtain an accuracy of 58.9% for the test dataset, which means that **the bias exists**. In order to know which adjectives influence more on the linguistic bias, we analyze their coefficients. The higher the coefficient, the more biased to female overviews and the lower the coefficient, the more biased to male overviews. Then, we analyze the subjectivity of these adjecitves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(df, num=100):\n",
    "    \"\"\"\n",
    "    get most common adjectives and return \n",
    "    \"\"\"\n",
    "    df = df.orderBy(desc(\"count\"))\n",
    "    df_pd = df.toPandas()\n",
    "    first_100_adj = df_pd[:num].copy()\n",
    "    return first_100_adj\n",
    "\n",
    "# get most common adjectives for male and female\n",
    "first_100_adj_male = most_common(most_common_adj_male, 100)\n",
    "first_100_adj_fem = most_common(most_common_adj_fem, 100)\n",
    "\n",
    "# create vocabulary for the model with the set of adjectives previous found\n",
    "most_common_adj = set()\n",
    "most_common_adj.update(first_100_adj_male['adjectives'].tolist())\n",
    "most_common_adj.update(first_100_adj_fem['adjectives'].tolist())\n",
    "most_common_adj = list(most_common_adj)\n",
    "print(\"Total size of vocabulary: {}\".format(len(most_common_adj)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_adjs(list_adj):\n",
    "    return len(list_adj)\n",
    "\n",
    "udf_get_n_adjs = udf(get_n_adjs)\n",
    "\n",
    "# generate df for the model \n",
    "def df_model(df):\n",
    "    df_model = df.select(\"id\", \"gender\", \"adjectives\")\n",
    "    df_model = df_model.withColumn(\"n-adjs\", udf_get_n_adjs(\"adjectives\"))\n",
    "    df_model = df_model.withColumn(\"gender\", udf_get_gender(\"gender\"))\n",
    "    return df_model\n",
    "    \n",
    "df_male_model = df_model(df_male)\n",
    "df_fem_model = df_model(df_fem)\n",
    "\n",
    "# convert to pandas\n",
    "df_male_pd = df_male_model.toPandas()\n",
    "df_fem_pd = df_fem_model.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input: one-hot coding\n",
    "def encode_input(list_words_present, list_adj_to_encode):\n",
    "    encoding = np.zeros(len(list_adj_to_encode))\n",
    "    for i, adj in enumerate(list_adj_to_encode):\n",
    "        if adj in list_words_present:\n",
    "            encoding[i] = 1\n",
    "    return encoding\n",
    "\n",
    "# encode gender\n",
    "def encode_output(gender):\n",
    "    return int(gender == 'female')\n",
    "\n",
    "# apply encoder to df\n",
    "def encode_df(df):\n",
    "    df['input'] = df.adjectives.map(lambda x: encode_input(x, most_common_adj))\n",
    "    df['output'] = df.gender.map(lambda x: encode_output(x))\n",
    "    \n",
    "\n",
    "encode_df(df_male_pd)\n",
    "encode_df(df_fem_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_male = len(df_male_pd)\n",
    "n_fem = len(df_fem_pd)\n",
    "assert n_male > n_fem\n",
    "\n",
    "# split data in test and train\n",
    "n_train = np.round(0.7 * n_fem).astype(np.uint)\n",
    "print(\"Number of entries for each gender on train: {}\".format(n_train))\n",
    "\n",
    "n_test = (n_fem - n_train).astype(np.uint)\n",
    "print(\"Number of entries for each gender on test: {}\".format(n_test))\n",
    "\n",
    "# select entries for the train and test df\n",
    "train_indices_fem = np.random.choice(range(n_fem), n_train, replace=False)\n",
    "test_indices_fem = np.setdiff1d(range(n_fem), train_indices_fem)\n",
    "\n",
    "train_indices_male = np.random.choice(range(n_male), n_train, replace=False)\n",
    "left_indices_male = np.setdiff1d(range(n_male), train_indices_male)\n",
    "test_indices_male = np.random.choice(left_indices_male, n_test, replace=False)\n",
    "\n",
    "# ensure balanced dataset\n",
    "assert len(train_indices_fem) == len(train_indices_male)\n",
    "assert len(test_indices_fem) == len(test_indices_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_output_gender(df):\n",
    "    X = np.stack(df.input)\n",
    "    y = np.stack(df.output)\n",
    "    return X,y\n",
    "\n",
    "def get_input_output(df_fem, df_male):\n",
    "    X_fem, y_fem = get_input_output_gender(df_fem)\n",
    "    X_male, y_male = get_input_output_gender(df_male)\n",
    "    \n",
    "    X = np.concatenate((X_fem, X_male), axis=0)\n",
    "    y = np.concatenate((y_fem, y_male), axis=0)\n",
    "    return X,y\n",
    "\n",
    "# build train df\n",
    "df_fem_train = df_fem_pd.iloc[train_indices_fem]\n",
    "df_male_train = df_male_pd.iloc[train_indices_male]\n",
    "\n",
    "# build test df\n",
    "df_fem_test = df_fem_pd.iloc[test_indices_fem]\n",
    "df_male_test = df_male_pd.iloc[test_indices_male]\n",
    "\n",
    "# get input, output from train data\n",
    "X_train, y_train = get_input_output(df_fem_train, df_male_train)\n",
    "print(\"Shape of train input:\\t{}\".format(X_train.shape))\n",
    "print(\"Shape of train output:\\t{}\".format(y_train.shape))\n",
    "\n",
    "# get input, output from train data\n",
    "X_test, y_test = get_input_output(df_fem_test, df_male_test)\n",
    "print(\"Shape of test input:\\t{}\".format(X_test.shape))\n",
    "print(\"Shape of test output:\\t{}\".format(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# train the model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix (true - rows, pred - cols)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# TODO: VISUALIZATION OF THE CONFUSION MATRIX! \n",
    "print('Confusion Matrix:\\n')\n",
    "print('T\\P \\t male \\t female')\n",
    "print('male \\t', cm[0,0], '\\t', cm[0,1])\n",
    "print('female \\t', cm[1,0], '\\t', cm[1,1])\n",
    "\n",
    "# accuracy\n",
    "print(\"\\n\\nAccuracy of the model in test dataset: {:.3f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities\n",
    "probs = lr.predict_proba(X_test)\n",
    "probs_pd = pd.DataFrame(probs, columns=['prob_male', 'prob_female'])\n",
    "probs_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas DataFrame with coefficients and its corresponding adjective\n",
    "data_pd = {'adjective': most_common_adj, 'coefficient': lr.coef_[0].tolist()}   \n",
    "df_coef = pd.DataFrame(data_pd) \n",
    "df_coef = df_coef.sort_values(by='coefficient', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjectivity(adj):\n",
    "    return subjectivity_dictionary.get(adj)[1]\n",
    "\n",
    "def get_strength(adj):\n",
    "    return subjectivity_dictionary.get(adj)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subjectivity and strength of the adjectives\n",
    "df_coef['subjectivity'] = df_coef['adjective'].map(lambda x: get_subjectivity(x))\n",
    "df_coef['strength'] = df_coef['adjective'].map(lambda x: get_strength(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adjectives correlated to female bias:\")\n",
    "df_coef.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adjectives correlated to male bias:\")\n",
    "df_coef.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the results above, we can see the adjectives more biased for both genders. In our next steps, we plan to deeper analyze them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Hola que tal :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
